{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Hello Clustering\n",
    "Recall from lecture that K-means has two main steps: the points assignment\n",
    "step, and the mean update step. After the initialization of the centroids, we\n",
    "assign each data point to a centroid. Then, each centroids are updated by\n",
    "re-estimating the means.\n",
    "Concretely, if we are given N data points, x1, x2, ..., xN , and we would like\n",
    "to form K clusters. We do the following;\n",
    "1. Initialization: Pick K random data points as K centroid locations c1,\n",
    "c2, ..., cK .\n",
    "2. Assign: For each data point k, find the closest centroid. Assign that\n",
    "data point to the centroid. The distance used is typically Euclidean distance.\n",
    "3. Update: For each centroid, calculate the mean from the data points\n",
    "assigned to it.\n",
    "4. Repeat: repeat step 2 and 3 until the centroids stop changing (conver-\n",
    "gence).\n",
    "Given the following data points in x-y coordinates (2 dimensional)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x y\n",
    "# 1 2\n",
    "# 3 3\n",
    "# 2 2\n",
    "# 8 8\n",
    "# 6 6\n",
    "# 7 7\n",
    "# -3 -3\n",
    "# -2 -4\n",
    "# -7 -7 \n",
    "# generate a list of points \n",
    "points = [(1,2),(3,3),(2,2),(8,8),(6,6),(7,7),(-3,-3),(-2,-4),(-7,-7)] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x13aecfd70>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the points \n",
    "x = [p[0] for p in points]\n",
    "y = [p[1] for p in points]\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmean cluster algorithm \n",
    "# 1. randomly select k points as centroids\n",
    "# 2. assign each point to the closest centroid\n",
    "# 3. calculate the new centroids\n",
    "# 4. repeat 2 and 3 until the centroids don't change\n",
    "# 5. the points in the same cluster are the points that are closest to the same centroid\n",
    "# 6. the number of clusters is k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def recalculate_centroids(points, cluster_assignment):\n",
    "    new_centroids = []\n",
    "    for i in range(np.max(cluster_assignment) + 1):\n",
    "        cluster_points = points[cluster_assignment == i]\n",
    "        centroid = np.mean(cluster_points, axis=0)\n",
    "        new_centroids.append(centroid)\n",
    "    return np.array(new_centroids)\n",
    "\n",
    "def kcluster(points, centroids):\n",
    "    points = np.array(points)\n",
    "    old_centroids = np.array(centroids)\n",
    "    while True:\n",
    "        print(\"old centroids : \" ,old_centroids)\n",
    "        # Expand dimensions for broadcasting\n",
    "        points_exp = np.expand_dims(points, axis=1)\n",
    "        centroids_exp = np.expand_dims(old_centroids, axis=0)\n",
    "        \n",
    "        # Calculate distances and assign points to clusters\n",
    "        distances = np.linalg.norm(points_exp - centroids_exp, axis=2)\n",
    "        cluster_assignment = np.argmin(distances, axis=1)\n",
    "        \n",
    "        # Recalculate centroids\n",
    "        new_centroids = recalculate_centroids(points, cluster_assignment)\n",
    "        \n",
    "        # If centroids haven't changed, we're done\n",
    "        if np.all(old_centroids == new_centroids):\n",
    "            break\n",
    "        \n",
    "        old_centroids = new_centroids\n",
    "    \n",
    "    return cluster_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T.5 If the starting points are (3,3), (2,2), and (-3,-3). Describe each\n",
    "assign and update step. What are the points assigned? What are the updated\n",
    "centroids? You may do this calculation by hand or write a program to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old centroids :  [[ 3  3]\n",
      " [ 2  2]\n",
      " [-3 -3]]\n",
      "old centroids :  [[ 6.          6.        ]\n",
      " [ 1.5         2.        ]\n",
      " [-4.         -4.66666667]]\n",
      "old centroids :  [[ 7.          7.        ]\n",
      " [ 2.          2.33333333]\n",
      " [-4.         -4.66666667]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x13aedfd70>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clusterT5 = kcluster(points, [(3,3),(2,2),(-3,-3)]) \n",
    "# plot cluster T5 \n",
    "x = [p[0] for p in points]\n",
    "y = [p[1] for p in points]\n",
    "plt.scatter(x,y,c=clusterT5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T.6 If the starting points are (-3,-3), (2,2), and (-7,-7), what happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old centroids :  [[-3 -3]\n",
      " [ 2  2]\n",
      " [-7 -7]]\n",
      "old centroids :  [[-2.5        -3.5       ]\n",
      " [ 4.5         4.66666667]\n",
      " [-7.         -7.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x13aef0050>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clusterT6 = kcluster(points, [(-3,-3),(2,2),(-7,-7)]) \n",
    "# plot cluster T6\n",
    "x = [p[0] for p in points]\n",
    "y = [p[1] for p in points]\n",
    "plt.scatter(x,y,c=clusterT6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My heart will go on1\n",
    "In this part of the exercise we will work on the Titanic dataset provided by\n",
    "Kaggle. The Titanic dataset contains information of the passengers boarding\n",
    "the Titanic on its final voyage. We will work on predicting whether a given\n",
    "passenger will survive the trip.\n",
    "Let’s launch Jupyter and start coding!\n",
    "We start by importing the data using Pandas\n",
    "train_url = \"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/train.csv\"\n",
    "train = pd.read_csv(train_url) #training set\n",
    "test_url = \"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/test.csv\"\n",
    "test = pd.read_csv(test_url) #test set\n",
    "Both train and test are dataframes. Use the function train.head() and\n",
    "train.tail() to explore the data. What do you see?\n",
    "Use the function describe() to get a better understanding of the data.\n",
    "You can read the meaning of the data fields at https://www.kaggle.com/c/\n",
    "titanic/data\n",
    "1Many parts of this exercise are adapted from Kaggle Python Tutorial on Machine Learning\n",
    "3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load df from csv \n",
    "df = pd.read_csv('Titanic_data/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T.8 What is the median age of the training set? You can easily modify\n",
    "the age in the dataframe by\n",
    "```\n",
    "train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].median())\n",
    "```\n",
    "Note that you need to modify the code above a bit to fill with mode() because\n",
    "mode() returns a series rather than a single value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T.9 Some fields like ‘Embarked’ are categorical. They need to be converted\n",
    "to numbers first. We will represent S with 0, C with 1, and Q with 2. What is\n",
    "the mode of Embarked? Fill the missing values with the mode. You can set the\n",
    "value of Embarked easily with the following command.\n",
    "ANd Do the same for Sex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "hm = {\n",
    "    'S': 0, \n",
    "    'C': 1,\n",
    "    'Q': 2\n",
    "}\n",
    "df['Embarked'] = df['Embarked'].map(hm) \n",
    "df.loc[df['Sex'] == 'male' ,'Sex'] = 0  \n",
    "df.loc[df['Sex'] == 'female' ,'Sex'] = 1\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T10. Write a logistic regression classifier using gradient descent as learned\n",
    "in class. Use PClass, Sex, Age, and Embarked as input features. You can\n",
    "extract the features from Pandas to Numpy by\n",
    "data = np.array(train[[\"PClass\",\"Sex\",\"Age\",\"Embarked\"]].values)\n",
    "Check the datatype of each values in data, does it make sense? You can\n",
    "force the data to be of any datatype by using the command\n",
    "data = np.array(train[[\"PClass\",\"Sex\",\"Age\",\"Embarked\"]].values, dtype = float)\n",
    "When you evaluate the trained model on the test set, you will need to make\n",
    "a final decision. Since logistic regression outputs a score between 0 and 1, you\n",
    "will need to decide whether a score of 0.3 (or any other number) means the\n",
    "passenger survive or not. For now, we will say if the score is greater than or\n",
    "equal to 0.5, the passenger survives. If the score is lower than 0.5 the passenger\n",
    "will be dead. This process is often called ‘Thresholding.’ We will talk more\n",
    "about this process later in class.\n",
    "To evaluate your results, we will use Kaggle. Kaggle is a website that hosts\n",
    "many machine learning competitions. Many companies put up their data as a\n",
    "problem for anyone to participate. If you are looking for a task for your course\n",
    "project, Kaggle might be a good place to start. You will need to make sure that\n",
    "your output is in line with the submission requirements of Kaggle: a csv file\n",
    "with exactly 418 entries and two columns: PassengerId and Survived. Then,\n",
    "4\n",
    "use the code provided to make a new data frame using DataFrame(), and create\n",
    "a csv file using to csv() method from Pandas.\n",
    "To submit your prediction, you must first sign-up for an account on Kaggle.\n",
    "com. Click participate to the competition at https://www.kaggle.com/c/\n",
    "titanic/ then submit your csv file for the score.\n",
    "The output file should have two columns: the passengerId and a 0,1 decision\n",
    "(0 for dead, 1 for survive). As shown below:\n",
    "PassengerId,Survived\n",
    "892,0\n",
    "893,1\n",
    "894,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = np.array(df[[\"Pclass\",\"Sex\",\"Age\",\"Embarked\"]].values, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.  0. 22.  0.]\n",
      " [ 1.  1. 38.  1.]\n",
      " [ 3.  1. 26.  0.]\n",
      " ...\n",
      " [ 3.  1. 28.  0.]\n",
      " [ 1.  0. 26.  1.]\n",
      " [ 3.  0. 32.  2.]]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize features\n",
    "def normalize_features(features):\n",
    "    print(\"features : \",features , \"mean : \",np.mean(features, axis=0) , \"std : \",np.std(features, axis=0))\n",
    "    return (features - np.mean(features, axis=0)) / np.std(features, axis=0)\n",
    "\n",
    "# Function to perform sigmoid activation\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Function to perform logistic regression using gradient descent\n",
    "def logistic_regression(X, y, learning_rate=0.000000000001, epochs=200000):\n",
    "    m, n = X.shape\n",
    "    X = np.hstack((np.ones((m, 1)), X))  # Add bias term\n",
    "\n",
    "    theta = np.zeros((n + 1, 1))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        h = sigmoid(np.dot(X, theta))\n",
    "        gradient = np.dot(X.T, (h - y)) / m\n",
    "        theta -= learning_rate * gradient\n",
    "\n",
    "    return theta\n",
    "\n",
    "# Function to predict labels based on trained logistic regression model\n",
    "def predict(X, theta, threshold=0.5):\n",
    "    X = np.hstack((np.ones((X.shape[0], 1)), X))  # Add bias term\n",
    "    probabilities = sigmoid(np.dot(X, theta))\n",
    "    predictions = (probabilities >= threshold).astype(int)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features :  [[ 3.  0. 22.  0.]\n",
      " [ 1.  1. 38.  1.]\n",
      " [ 3.  1. 26.  0.]\n",
      " ...\n",
      " [ 3.  1. 28.  0.]\n",
      " [ 1.  0. 26.  1.]\n",
      " [ 3.  0. 32.  2.]] mean :  [ 2.30864198  0.35241302 29.36158249  0.36139169] std :  [ 0.83560193  0.47772176 13.01238827  0.63531665]\n"
     ]
    }
   ],
   "source": [
    "# Extract features and labels\n",
    "X_train = np.array(df[[\"Pclass\", \"Sex\", \"Age\", \"Embarked\"]].values, dtype=float)\n",
    "y_train = np.array(df[\"Survived\"].values).reshape(-1, 1)\n",
    "\n",
    "# Normalize features\n",
    "X_train = normalize_features(X_train)\n",
    "\n",
    "# Train logistic regression model\n",
    "theta = logistic_regression(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('Titanic_data/test.csv')\n",
    "\n",
    "test.loc[test['Sex'] == 'male', 'Sex'] = 0\n",
    "test.loc[test['Sex'] == 'female', 'Sex'] = 1\n",
    "hm = {\n",
    "    'S': 0, \n",
    "    'C': 1,\n",
    "    'Q': 2\n",
    "}\n",
    "test['Embarked'] = test['Embarked'].map(hm) \n",
    "test['Age'] = test['Age'].fillna(test['Age'].median())\n",
    "\n",
    "test['Embarked'] = test['Embarked'].fillna(test['Embarked'].mode()[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features :  [[ 3.   0.  34.5  2. ]\n",
      " [ 3.   1.  47.   0. ]\n",
      " [ 2.   0.  62.   2. ]\n",
      " ...\n",
      " [ 3.   0.  38.5  0. ]\n",
      " [ 3.   0.  27.   0. ]\n",
      " [ 3.   0.  27.   1. ]] mean :  [ 2.26555024  0.36363636 29.5992823   0.46411483] std :  [ 0.84082997  0.48104569 12.68856485  0.68469552]\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "\n",
    "# Extract features from test data\n",
    "X_test = np.array(test[[\"Pclass\", \"Sex\", \"Age\", \"Embarked\"]].values, dtype=float)\n",
    "\n",
    "# Normalize test features\n",
    "X_test = normalize_features(X_test)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = predict(X_test, theta)\n",
    "\n",
    "# Create a DataFrame for Kaggle submission\n",
    "submission_df = pd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Survived\": predictions.flatten()})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T 11. Try adding some higher order features to your training (x21, x1x2,...).\n",
    "Does this model has better accuracy on the training set? How does it\n",
    "perform on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features :  [[ 3.  0. 22.  0.  9.  0.]\n",
      " [ 1.  1. 38.  1.  1.  1.]\n",
      " [ 3.  1. 26.  0.  9.  3.]\n",
      " ...\n",
      " [ 3.  1. 28.  0.  9.  3.]\n",
      " [ 1.  0. 26.  1.  1.  0.]\n",
      " [ 3.  0. 32.  2.  9.  0.]] mean :  [ 2.30864198  0.35241302 29.36158249  0.36139169  6.02805836  0.76094276] std :  [ 0.83560193  0.47772176 13.01238827  0.63531665  3.44172238  1.14986985]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract features and labels\n",
    "X_train = np.array(df[[\"Pclass\", \"Sex\", \"Age\", \"Embarked\"]].values, dtype=float)\n",
    "y_train = np.array(df[\"Survived\"].values).reshape(-1, 1)\n",
    "# Add higher order features\n",
    "X_train = np.hstack((X_train, X_train[:, 0:1]**2, X_train[:, 0:1]*X_train[:, 1:2]))\n",
    "# Normalize features\n",
    "X_train = normalize_features(X_train)\n",
    "# # Train logistic regression model\n",
    "theta = logistic_regression(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>0</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                          Name Sex  \\\n",
       "0            892       3                              Kelly, Mr. James   0   \n",
       "1            893       3              Wilkes, Mrs. James (Ellen Needs)   1   \n",
       "2            894       2                     Myles, Mr. Thomas Francis   0   \n",
       "3            895       3                              Wirz, Mr. Albert   0   \n",
       "4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   1   \n",
       "..           ...     ...                                           ...  ..   \n",
       "413         1305       3                            Spector, Mr. Woolf   0   \n",
       "414         1306       1                  Oliva y Ocana, Dona. Fermina   1   \n",
       "415         1307       3                  Saether, Mr. Simon Sivertsen   0   \n",
       "416         1308       3                           Ware, Mr. Frederick   0   \n",
       "417         1309       3                      Peter, Master. Michael J   0   \n",
       "\n",
       "      Age  SibSp  Parch              Ticket      Fare Cabin  Embarked  \n",
       "0    34.5      0      0              330911    7.8292   NaN         2  \n",
       "1    47.0      1      0              363272    7.0000   NaN         0  \n",
       "2    62.0      0      0              240276    9.6875   NaN         2  \n",
       "3    27.0      0      0              315154    8.6625   NaN         0  \n",
       "4    22.0      1      1             3101298   12.2875   NaN         0  \n",
       "..    ...    ...    ...                 ...       ...   ...       ...  \n",
       "413  27.0      0      0           A.5. 3236    8.0500   NaN         0  \n",
       "414  39.0      0      0            PC 17758  108.9000  C105         1  \n",
       "415  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN         0  \n",
       "416  27.0      0      0              359309    8.0500   NaN         0  \n",
       "417  27.0      1      1                2668   22.3583   NaN         1  \n",
       "\n",
       "[418 rows x 11 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features :  [[ 3.   0.  34.5  2.   9.   0. ]\n",
      " [ 3.   1.  47.   0.   9.   3. ]\n",
      " [ 2.   0.  62.   2.   4.   0. ]\n",
      " ...\n",
      " [ 3.   0.  38.5  0.   9.   0. ]\n",
      " [ 3.   0.  27.   0.   9.   0. ]\n",
      " [ 3.   0.  27.   1.   9.   0. ]] mean :  [ 2.26555024  0.36363636 29.5992823   0.46411483  5.83971292  0.77990431] std :  [ 0.84082997  0.48104569 12.68856485  0.68469552  3.45797074  1.16132987]\n"
     ]
    }
   ],
   "source": [
    "X_test = np.array(test[[\"Pclass\", \"Sex\", \"Age\", \"Embarked\"]].values, dtype=float)\n",
    "X_test = np.hstack((X_test, X_test[:, 0:1]**2, X_test[:, 0:1]*X_test[:, 1:2]))\n",
    "X_test = normalize_features(X_test)\n",
    "predictions = predict(X_test, theta)\n",
    "# Create a DataFrame for Kaggle submission\n",
    "submission_df = pd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Survived\": predictions.flatten()})\n",
    "# Save the DataFrame to a CSV file\n",
    "submission_df.to_csv(\"submission2.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T13. What happens if you reduce the amount of features to just Sex and\n",
    "Age?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features :  [[ 0. 22.]\n",
      " [ 1. 38.]\n",
      " [ 1. 26.]\n",
      " ...\n",
      " [ 1. 28.]\n",
      " [ 0. 26.]\n",
      " [ 0. 32.]] mean :  [ 0.35241302 29.36158249] std :  [ 0.47772176 13.01238827]\n"
     ]
    }
   ],
   "source": [
    "# Extract features and labels\n",
    "X_train = np.array(df[[\"Sex\", \"Age\"]].values, dtype=float)\n",
    "y_train = np.array(df[\"Survived\"].values).reshape(-1, 1)\n",
    "\n",
    "# Normalize features\n",
    "X_train = normalize_features(X_train)\n",
    "\n",
    "# Train logistic regression model\n",
    "theta = logistic_regression(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features :  [[ 0.   34.5 ]\n",
      " [ 1.   47.  ]\n",
      " [ 0.   62.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 1.   22.  ]\n",
      " [ 0.   14.  ]\n",
      " [ 1.   30.  ]\n",
      " [ 0.   26.  ]\n",
      " [ 1.   18.  ]\n",
      " [ 0.   21.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   46.  ]\n",
      " [ 1.   23.  ]\n",
      " [ 0.   63.  ]\n",
      " [ 1.   47.  ]\n",
      " [ 1.   24.  ]\n",
      " [ 0.   35.  ]\n",
      " [ 0.   21.  ]\n",
      " [ 1.   27.  ]\n",
      " [ 1.   45.  ]\n",
      " [ 0.   55.  ]\n",
      " [ 0.    9.  ]\n",
      " [ 1.   27.  ]\n",
      " [ 0.   21.  ]\n",
      " [ 1.   48.  ]\n",
      " [ 0.   50.  ]\n",
      " [ 1.   22.  ]\n",
      " [ 0.   22.5 ]\n",
      " [ 0.   41.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   50.  ]\n",
      " [ 0.   24.  ]\n",
      " [ 1.   33.  ]\n",
      " [ 1.   27.  ]\n",
      " [ 0.   30.  ]\n",
      " [ 0.   18.5 ]\n",
      " [ 1.   27.  ]\n",
      " [ 1.   21.  ]\n",
      " [ 0.   25.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   39.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   41.  ]\n",
      " [ 1.   30.  ]\n",
      " [ 1.   45.  ]\n",
      " [ 0.   25.  ]\n",
      " [ 0.   45.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 1.   60.  ]\n",
      " [ 1.   36.  ]\n",
      " [ 0.   24.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 1.   20.  ]\n",
      " [ 1.   28.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   10.  ]\n",
      " [ 0.   35.  ]\n",
      " [ 0.   25.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 1.   36.  ]\n",
      " [ 0.   17.  ]\n",
      " [ 0.   32.  ]\n",
      " [ 0.   18.  ]\n",
      " [ 1.   22.  ]\n",
      " [ 0.   13.  ]\n",
      " [ 1.   27.  ]\n",
      " [ 1.   18.  ]\n",
      " [ 0.   47.  ]\n",
      " [ 0.   31.  ]\n",
      " [ 1.   60.  ]\n",
      " [ 1.   24.  ]\n",
      " [ 0.   21.  ]\n",
      " [ 1.   29.  ]\n",
      " [ 0.   28.5 ]\n",
      " [ 1.   35.  ]\n",
      " [ 0.   32.5 ]\n",
      " [ 0.   27.  ]\n",
      " [ 1.   55.  ]\n",
      " [ 0.   30.  ]\n",
      " [ 1.   24.  ]\n",
      " [ 0.    6.  ]\n",
      " [ 0.   67.  ]\n",
      " [ 0.   49.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 1.   27.  ]\n",
      " [ 1.   18.  ]\n",
      " [ 1.   27.  ]\n",
      " [ 0.    2.  ]\n",
      " [ 1.   22.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 1.   27.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   25.  ]\n",
      " [ 0.   25.  ]\n",
      " [ 1.   76.  ]\n",
      " [ 0.   29.  ]\n",
      " [ 1.   20.  ]\n",
      " [ 0.   33.  ]\n",
      " [ 1.   43.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   26.  ]\n",
      " [ 1.   16.  ]\n",
      " [ 0.   28.  ]\n",
      " [ 0.   21.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   18.5 ]\n",
      " [ 0.   41.  ]\n",
      " [ 1.   27.  ]\n",
      " [ 1.   36.  ]\n",
      " [ 1.   18.5 ]\n",
      " [ 1.   63.  ]\n",
      " [ 0.   18.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 1.    1.  ]\n",
      " [ 0.   36.  ]\n",
      " [ 1.   29.  ]\n",
      " [ 1.   12.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 1.   35.  ]\n",
      " [ 0.   28.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 1.   17.  ]\n",
      " [ 0.   22.  ]\n",
      " [ 1.   27.  ]\n",
      " [ 0.   42.  ]\n",
      " [ 0.   24.  ]\n",
      " [ 0.   32.  ]\n",
      " [ 0.   53.  ]\n",
      " [ 1.   27.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   43.  ]\n",
      " [ 0.   24.  ]\n",
      " [ 0.   26.5 ]\n",
      " [ 0.   26.  ]\n",
      " [ 1.   23.  ]\n",
      " [ 0.   40.  ]\n",
      " [ 1.   10.  ]\n",
      " [ 1.   33.  ]\n",
      " [ 0.   61.  ]\n",
      " [ 0.   28.  ]\n",
      " [ 0.   42.  ]\n",
      " [ 0.   31.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   22.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   30.  ]\n",
      " [ 1.   23.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   60.5 ]\n",
      " [ 1.   36.  ]\n",
      " [ 0.   13.  ]\n",
      " [ 0.   24.  ]\n",
      " [ 1.   29.  ]\n",
      " [ 1.   23.  ]\n",
      " [ 0.   42.  ]\n",
      " [ 1.   26.  ]\n",
      " [ 1.   27.  ]\n",
      " [ 0.    7.  ]\n",
      " [ 1.   26.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   41.  ]\n",
      " [ 1.   26.  ]\n",
      " [ 0.   48.  ]\n",
      " [ 0.   18.  ]\n",
      " [ 1.   27.  ]\n",
      " [ 1.   22.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   23.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   40.  ]\n",
      " [ 1.   15.  ]\n",
      " [ 1.   20.  ]\n",
      " [ 0.   54.  ]\n",
      " [ 1.   36.  ]\n",
      " [ 1.   64.  ]\n",
      " [ 0.   30.  ]\n",
      " [ 0.   37.  ]\n",
      " [ 1.   18.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 1.   27.  ]\n",
      " [ 0.   40.  ]\n",
      " [ 1.   21.  ]\n",
      " [ 0.   17.  ]\n",
      " [ 1.   27.  ]\n",
      " [ 0.   40.  ]\n",
      " [ 0.   34.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   11.5 ]\n",
      " [ 0.   61.  ]\n",
      " [ 0.    8.  ]\n",
      " [ 0.   33.  ]\n",
      " [ 0.    6.  ]\n",
      " [ 1.   18.  ]\n",
      " [ 0.   23.  ]\n",
      " [ 1.   27.  ]\n",
      " [ 1.   27.  ]\n",
      " [ 0.    0.33]\n",
      " [ 0.   47.  ]\n",
      " [ 1.    8.  ]\n",
      " [ 0.   25.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 1.   35.  ]\n",
      " [ 0.   24.  ]\n",
      " [ 1.   33.  ]\n",
      " [ 0.   25.  ]\n",
      " [ 0.   32.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   17.  ]\n",
      " [ 1.   60.  ]\n",
      " [ 1.   38.  ]\n",
      " [ 0.   42.  ]\n",
      " [ 1.   27.  ]\n",
      " [ 0.   57.  ]\n",
      " [ 1.   50.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 1.   30.  ]\n",
      " [ 0.   21.  ]\n",
      " [ 1.   22.  ]\n",
      " [ 0.   21.  ]\n",
      " [ 1.   53.  ]\n",
      " [ 1.   27.  ]\n",
      " [ 0.   23.  ]\n",
      " [ 1.   27.  ]\n",
      " [ 0.   40.5 ]\n",
      " [ 0.   36.  ]\n",
      " [ 0.   14.  ]\n",
      " [ 1.   21.  ]\n",
      " [ 0.   21.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   39.  ]\n",
      " [ 0.   20.  ]\n",
      " [ 0.   64.  ]\n",
      " [ 0.   20.  ]\n",
      " [ 1.   18.  ]\n",
      " [ 1.   48.  ]\n",
      " [ 1.   55.  ]\n",
      " [ 1.   45.  ]\n",
      " [ 0.   45.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   41.  ]\n",
      " [ 1.   22.  ]\n",
      " [ 0.   42.  ]\n",
      " [ 1.   29.  ]\n",
      " [ 1.   27.  ]\n",
      " [ 1.    0.92]\n",
      " [ 0.   20.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   24.  ]\n",
      " [ 0.   32.5 ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   28.  ]\n",
      " [ 1.   19.  ]\n",
      " [ 0.   21.  ]\n",
      " [ 0.   36.5 ]\n",
      " [ 0.   21.  ]\n",
      " [ 1.   29.  ]\n",
      " [ 1.    1.  ]\n",
      " [ 0.   30.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 1.   27.  ]\n",
      " [ 0.   17.  ]\n",
      " [ 0.   46.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 1.   26.  ]\n",
      " [ 1.   27.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 1.   20.  ]\n",
      " [ 0.   28.  ]\n",
      " [ 0.   40.  ]\n",
      " [ 0.   30.  ]\n",
      " [ 0.   22.  ]\n",
      " [ 1.   23.  ]\n",
      " [ 0.    0.75]\n",
      " [ 1.   27.  ]\n",
      " [ 1.    9.  ]\n",
      " [ 1.    2.  ]\n",
      " [ 0.   36.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   24.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 1.   30.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   53.  ]\n",
      " [ 0.   36.  ]\n",
      " [ 0.   26.  ]\n",
      " [ 1.    1.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   30.  ]\n",
      " [ 0.   29.  ]\n",
      " [ 0.   32.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   43.  ]\n",
      " [ 0.   24.  ]\n",
      " [ 1.   27.  ]\n",
      " [ 1.   64.  ]\n",
      " [ 0.   30.  ]\n",
      " [ 0.    0.83]\n",
      " [ 0.   55.  ]\n",
      " [ 1.   45.  ]\n",
      " [ 0.   18.  ]\n",
      " [ 0.   22.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 1.   37.  ]\n",
      " [ 1.   55.  ]\n",
      " [ 1.   17.  ]\n",
      " [ 0.   57.  ]\n",
      " [ 0.   19.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   22.  ]\n",
      " [ 0.   26.  ]\n",
      " [ 0.   25.  ]\n",
      " [ 0.   26.  ]\n",
      " [ 0.   33.  ]\n",
      " [ 1.   39.  ]\n",
      " [ 0.   23.  ]\n",
      " [ 1.   12.  ]\n",
      " [ 0.   46.  ]\n",
      " [ 0.   29.  ]\n",
      " [ 0.   21.  ]\n",
      " [ 1.   48.  ]\n",
      " [ 0.   39.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 1.   19.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   30.  ]\n",
      " [ 0.   32.  ]\n",
      " [ 0.   39.  ]\n",
      " [ 0.   25.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   18.  ]\n",
      " [ 0.   32.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 1.   58.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 1.   16.  ]\n",
      " [ 0.   26.  ]\n",
      " [ 1.   38.  ]\n",
      " [ 0.   24.  ]\n",
      " [ 1.   31.  ]\n",
      " [ 1.   45.  ]\n",
      " [ 0.   25.  ]\n",
      " [ 0.   18.  ]\n",
      " [ 0.   49.  ]\n",
      " [ 1.    0.17]\n",
      " [ 0.   50.  ]\n",
      " [ 1.   59.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 1.   30.  ]\n",
      " [ 0.   14.5 ]\n",
      " [ 1.   24.  ]\n",
      " [ 1.   31.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 1.   25.  ]\n",
      " [ 1.   27.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 1.   22.  ]\n",
      " [ 1.   45.  ]\n",
      " [ 0.   29.  ]\n",
      " [ 0.   21.  ]\n",
      " [ 1.   31.  ]\n",
      " [ 0.   49.  ]\n",
      " [ 0.   44.  ]\n",
      " [ 1.   54.  ]\n",
      " [ 1.   45.  ]\n",
      " [ 1.   22.  ]\n",
      " [ 0.   21.  ]\n",
      " [ 0.   55.  ]\n",
      " [ 0.    5.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   26.  ]\n",
      " [ 1.   27.  ]\n",
      " [ 1.   19.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 1.   24.  ]\n",
      " [ 0.   24.  ]\n",
      " [ 0.   57.  ]\n",
      " [ 0.   21.  ]\n",
      " [ 0.    6.  ]\n",
      " [ 0.   23.  ]\n",
      " [ 1.   51.  ]\n",
      " [ 0.   13.  ]\n",
      " [ 0.   47.  ]\n",
      " [ 0.   29.  ]\n",
      " [ 1.   18.  ]\n",
      " [ 0.   24.  ]\n",
      " [ 1.   48.  ]\n",
      " [ 0.   22.  ]\n",
      " [ 0.   31.  ]\n",
      " [ 1.   30.  ]\n",
      " [ 0.   38.  ]\n",
      " [ 1.   22.  ]\n",
      " [ 0.   17.  ]\n",
      " [ 0.   43.  ]\n",
      " [ 0.   20.  ]\n",
      " [ 0.   23.  ]\n",
      " [ 0.   50.  ]\n",
      " [ 1.   27.  ]\n",
      " [ 1.    3.  ]\n",
      " [ 1.   27.  ]\n",
      " [ 1.   37.  ]\n",
      " [ 1.   28.  ]\n",
      " [ 0.   27.  ]\n",
      " [ 1.   39.  ]\n",
      " [ 0.   38.5 ]\n",
      " [ 0.   27.  ]\n",
      " [ 0.   27.  ]] mean :  [ 0.36363636 29.5992823 ] std :  [ 0.48104569 12.68856485]\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "\n",
    "# Extract features from test data\n",
    "X_test = np.array(test[[\"Sex\", \"Age\"]].values, dtype=float)\n",
    "\n",
    "# Normalize test features\n",
    "X_test = normalize_features(X_test)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = predict(X_test, theta)\n",
    "\n",
    "# Create a DataFrame for Kaggle submission\n",
    "submission_df = pd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Survived\": predictions.flatten()})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "submission_df.to_csv(\"submission3.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pattern",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
